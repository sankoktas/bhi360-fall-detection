{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell is used to find the features that distinguish motion from no motion the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def _f1(cm, idx):\n",
    "    tp = cm[idx, idx]\n",
    "    fn = cm[idx, :].sum() - tp\n",
    "    fp = cm[:, idx].sum() - tp\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "def print_combined_metrics(cm, labels):\n",
    "    \"\"\"\n",
    "    Print precision, recall, F1 for each class + return macro F1 for FALL and MOTION only.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Class-wise Precision, Recall, F1:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        tp = cm[i, i]\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        print(f\"{label}: Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")\n",
    "\n",
    "    macro_f1 = 0\n",
    "    try:\n",
    "        fall_idx = list(labels).index(\"FALL\")\n",
    "        motion_idx = list(labels).index(\"MOTION\")\n",
    "        fall_f1 = _f1(cm, fall_idx)\n",
    "        motion_f1 = _f1(cm, motion_idx)\n",
    "        macro_f1 = (fall_f1 + motion_f1) / 2\n",
    "        print(f\"\\n‚≠ê Macro F1 (FALL vs MOTION): {macro_f1:.4f}\")\n",
    "    except ValueError:\n",
    "        print(\"\\n‚ö†Ô∏è FALL or MOTION not found in labels. Skipping macro F1 calc.\")\n",
    "\n",
    "    return macro_f1\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Run LOSO CV on top feature combos + merged hybrids.\n",
    "    Print confusion matrices and metrics, and identify the best-performing combo.\n",
    "    \"\"\"\n",
    "    original_combos = [\n",
    "        ['acc_mag_iqr', 'acc_impact_peak_val', 'tilt_angle_mean'],\n",
    "        ['acc_mag_range', 'acc_mag_rms', 'acc_x_range'],\n",
    "        ['acc_mag_rms', 'acc_num_peaks', 'gyro_mag_median'],\n",
    "        ['acc_mag_rms', 'sma', 'acc_y_range'],\n",
    "        ['acc_mag_rms', 'acc_y_range', 'acc_mag_p75'],\n",
    "        ['acc_mag_rms', 'acc_x_range', 'acc_y_range'],\n",
    "        ['acc_num_peaks', 'tilt_angle_mean', 'acc_x_range']\n",
    "    ]\n",
    "\n",
    "    # Generate merged combos (up to 7 features per combo)\n",
    "    hybrid_combos = []\n",
    "    for c1, c2 in combinations(original_combos, 2):\n",
    "        merged = sorted(set(c1) | set(c2))\n",
    "        if len(merged) <= 7:\n",
    "            hybrid_combos.append(merged)\n",
    "\n",
    "    all_combos = original_combos + hybrid_combos\n",
    "    print(f\"\\nüî¢ Total combinations to evaluate: {len(all_combos)}\")\n",
    "\n",
    "    best_params = {'learning_rate': 0.01, 'max_iter': 200, 'max_leaf_nodes': 31}\n",
    "\n",
    "    best_score = -1\n",
    "    best_combo = None\n",
    "    best_cm = None\n",
    "    best_labels = None\n",
    "\n",
    "    for i, selected_features in enumerate(all_combos, 1):\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nüîç Combo {i}/{len(all_combos)}: {selected_features}\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "        session_results, le, labels = loso_cv_print_each(df_features, selected_features, best_params)\n",
    "\n",
    "        combined_cm = np.zeros_like(session_results[0][2])\n",
    "        for _, _, cm in session_results:\n",
    "            combined_cm += cm\n",
    "\n",
    "        print(\"\\nCombined Confusion Matrix:\")\n",
    "        print(combined_cm)\n",
    "        plot_row_normalized_confusion_matrix(combined_cm, labels, f\"Combo {i} Confusion Matrix (Row-Normalized)\")\n",
    "        macro_f1 = print_combined_metrics(combined_cm, labels)\n",
    "\n",
    "        # Track best\n",
    "        if macro_f1 > best_score:\n",
    "            best_score = macro_f1\n",
    "            best_combo = selected_features\n",
    "            best_cm = combined_cm\n",
    "            best_labels = labels\n",
    "\n",
    "    # Final best result\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üèÜ BEST COMBINATION FOUND:\")\n",
    "    print(\"Features:\", best_combo)\n",
    "    print(f\"Macro F1 Score (Fall vs Motion): {best_score:.4f}\")\n",
    "    print(\"Combined Confusion Matrix:\")\n",
    "    print(best_cm)\n",
    "    plot_row_normalized_confusion_matrix(best_cm, best_labels, \"Best Combo Confusion Matrix (Row-Normalized)\")\n",
    "    print_combined_metrics(best_cm, best_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = read_data(\"training_data.csv\")\n",
    "df_features = extract_advanced_features_from_timeseries(df_raw, window_size=2, step_size=0.25, do_fft=True)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
